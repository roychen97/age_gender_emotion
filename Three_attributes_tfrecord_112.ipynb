{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"   \n",
    "import random\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras as K\n",
    "from tensorflow.python.framework import ops\n",
    "#%matplotlib inline\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "\n",
    "from PIL import Image\n",
    "# Import MNIST data\n",
    "\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.ImageOps  as ImageOps\n",
    "from PIL import Image, ImageDraw\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "print (\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow.compat.v1 as tff\n",
    "#tff.disable_v2_behavior()\n",
    "#v1=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[2], True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "\n",
    "\n",
    "config = ConfigProto(gpu_options=gpu_options)\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "#import imageio as im\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.backend import *\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import *\n",
    "\"\"\"\n",
    "def customLoss(yTrue,yPred):\n",
    "    \n",
    "    loss_op=(\n",
    "    #mean_squared_error(yTrue, yPred)\n",
    "        logcosh(yTrue, yPred)\n",
    "    )\n",
    "    return loss_op\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def ageLoss(yTrue,yPred):\n",
    "    ageYTrue=yTrue[:,0]\n",
    "    ageYPred=yPred[:,0]\n",
    "\n",
    "    \n",
    "    ageYTrue_masked = tf.boolean_mask(ageYTrue, tf.not_equal(ageYTrue, -1))\n",
    "    ageYPred_masked = tf.boolean_mask(ageYPred, tf.not_equal(ageYTrue, -1))\n",
    "    \n",
    "\n",
    "    \n",
    "    ageLoss=tf.keras.losses.logcosh(ageYTrue_masked, ageYPred_masked)\n",
    "    \n",
    " \n",
    "    \n",
    "    loss_op=(\n",
    "       K.mean(ageLoss)\n",
    "    )\n",
    "    \n",
    "    return loss_op\n",
    "\n",
    "\n",
    "def genderLoss(yTrue,yPred):\n",
    "\n",
    "    genderYTrue=yTrue[:,1]\n",
    "    genderYPred=yPred[:,1:3]\n",
    "\n",
    "    \n",
    "    genderYTrue_masked = tf.boolean_mask(genderYTrue, tf.not_equal(genderYTrue, -1))\n",
    "    genderYPred_masked = tf.boolean_mask(genderYPred, tf.not_equal(genderYTrue, -1))\n",
    "    \n",
    "\n",
    "    \n",
    "    genderLoss=tf.keras.losses.sparse_categorical_crossentropy(genderYTrue_masked,genderYPred_masked)\n",
    "    \n",
    " \n",
    "    \n",
    "    loss_op=(\n",
    "       K.mean(genderLoss)*12\n",
    "    )\n",
    "    \n",
    "    return loss_op\n",
    "\n",
    "\n",
    "def emoLoss(yTrue,yPred):\n",
    "\n",
    "    emoYTrue=yTrue[:,2]\n",
    "    emoYPred=yPred[:,3:9]\n",
    "\n",
    "    \n",
    "    emoYTrue_masked = tf.boolean_mask(emoYTrue, tf.not_equal(emoYTrue, -1))\n",
    "    emoYPred_masked = tf.boolean_mask(emoYPred, tf.not_equal(emoYTrue, -1))\n",
    "    \n",
    "\n",
    "    \n",
    "    emoLoss=tf.keras.losses.sparse_categorical_crossentropy(emoYTrue_masked,emoYPred_masked)\n",
    "    \n",
    " \n",
    "    \n",
    "    loss_op=(\n",
    "       K.mean(emoLoss)*8\n",
    "    )\n",
    "    \n",
    "    return loss_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datapath='./dataarray/three_attributes/'\n",
    "inputarraytrain=np.load(datapath+'theImageArraytrain.npy')\n",
    "inputarraytest=np.load(datapath+'theImageArraytest.npy')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labelarraytrain=np.load(datapath+'theLabelArraytrain.npy')\n",
    "labelarraytest=np.load(datapath+'theLabelArraytest.npy')\n",
    "\n",
    "namearraytrain=np.load(datapath+'theNameArraytrain.npy')\n",
    "namearraytest=np.load(datapath+'theNameArraytest.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "print(type(inputarraytrain[0][0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _relu6(x):\n",
    "    \"\"\"Relu 6\n",
    "    \"\"\"\n",
    "    return K.relu(x, max_value=6.0)\n",
    "\n",
    "def _hard_swish(x):\n",
    "\n",
    "\n",
    "    return x * K.relu(x + 3.0, max_value=6.0) / 6.0\n",
    "\n",
    "def _return_activation( x, nl):\n",
    "\n",
    "    if nl == 'HS':\n",
    "        x = Activation(_hard_swish)(x)\n",
    "    if nl == 'RE':\n",
    "        x = Activation(_relu6)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def _conv_block(inputs, filters, kernel, strides, nl):\n",
    "\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x = Conv2D(filters, kernel, padding='same', strides=strides)(inputs)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "    return _return_activation(x, nl)\n",
    "\n",
    "\n",
    "def _bottleneck( inputs, filters, kernel, e, s, squeeze, nl):\n",
    "\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    input_shape = K.int_shape(inputs)\n",
    "    tchannel = input_shape[channel_axis] * e\n",
    "    r = s == 1 and input_shape[3] == filters\n",
    "\n",
    "    x = _conv_block(inputs, tchannel, (1, 1), (1, 1), nl)\n",
    "\n",
    "    x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "    if squeeze:\n",
    "        input_channels = x.shape[-1]\n",
    "        x1 = GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x1 = Dense(input_channels, activation='relu')(x1)\n",
    "        x1 = Dense(input_channels, activation='hard_sigmoid')(x1)\n",
    "        x1= Reshape((1,1,input_channels))(x1)\n",
    "\n",
    "        x = Multiply()([x, x1])\n",
    "\n",
    "\n",
    "\n",
    "    x = _return_activation(x, nl)\n",
    "\n",
    "    x = Conv2D(filters, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "    if r:\n",
    "        x = Add()([x, inputs])\n",
    "\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scalling:1 1.2 day, gendeaccu:93.7 age25peraccu=63.7 agemeandiff=8\n",
    "\n",
    "#small\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Reshape\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MobileNetV3_Large(shape,n_class,scalling):\n",
    "\n",
    "    inputs = Input(shape=shape)\n",
    "\n",
    "    x = _conv_block(inputs, int(16*scalling), (3, 3), strides=(2, 2), nl='HS')\n",
    "    \n",
    "    x = _bottleneck(x, int(20*scalling), (3, 3), e=1, s=1, squeeze=True, nl='RE')\n",
    "    x =  _bottleneck(x, int(24*scalling), (3, 3), e=2, s=2, squeeze=True, nl='RE')\n",
    "    x =  _bottleneck(x, int(24*scalling), (3, 3), e=3, s=1, squeeze=False, nl='RE')\n",
    "    x =  _bottleneck(x, int(40*scalling), (5, 5), e=4, s=2, squeeze=True, nl='HS')\n",
    "    x =  _bottleneck(x, int(40*scalling), (5, 5), e=6, s=1, squeeze=True, nl='HS')\n",
    "    x =  _bottleneck(x, int(40*scalling), (5, 5), e=6, s=1, squeeze=True, nl='HS')\n",
    "    x =  _bottleneck(x, int(48*scalling), (5, 5), e=3, s=1, squeeze=True, nl='HS')\n",
    "    x =  _bottleneck(x, int(48*scalling), (5, 5), e=3, s=1, squeeze=True, nl='HS')\n",
    "    x =  _bottleneck(x, int(96*scalling), (5, 5), e=6, s=2, squeeze=True, nl='HS')\n",
    "    x =  _bottleneck(x, int(96*scalling), (5, 5), e=6, s=1, squeeze=True, nl='HS')\n",
    "    x =  _bottleneck(x, int(120*scalling), (5, 5), e=6, s=1, squeeze=True, nl='HS')\n",
    "\n",
    "    x =  _conv_block(x, int(576*scalling), (1, 1), strides=(1, 1), nl='HS')\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Reshape((1, 1, int(576*scalling)))(x)\n",
    "\n",
    "    x = Conv2D(int(1280*scalling), (1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x =  _return_activation(x, 'HS')\n",
    "    \n",
    "    x=Dropout(0.5)(x)\n",
    "    xage = Conv2D(1, (1, 1), padding='same')(x)\n",
    "    xgender=Conv2D(2, (1, 1), padding='same', activation='softmax')(x)\n",
    "    xemo=Conv2D(6, (1, 1), padding='same', activation='softmax')(x)\n",
    "    xconcate=Concatenate()([xage,xgender,xemo])\n",
    "    output = Reshape((9,))(xconcate)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Reshape\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MobileNetV3_Large(shape,n_class,scalling):\n",
    "\n",
    "    inputs = Input(shape=shape)\n",
    "\n",
    "    x = _conv_block(inputs, int(16*scalling), (3, 3), strides=(2, 2), nl='HS')\n",
    "    \n",
    "\n",
    "    x =  _bottleneck(x, int(24*scalling), (3, 3), e=2, s=2, squeeze=True, nl='RE')\n",
    "    x =  _bottleneck(x, int(24*scalling), (3, 3), e=3, s=1, squeeze=False, nl='RE')\n",
    "    x =  _bottleneck(x, int(40*scalling), (5, 5), e=4, s=2, squeeze=True, nl='HS')\n",
    "    x =  _bottleneck(x, int(40*scalling), (5, 5), e=6, s=1, squeeze=True, nl='HS')\n",
    "    x =  _bottleneck(x, int(40*scalling), (5, 5), e=6, s=1, squeeze=True, nl='HS')\n",
    "    x =  _bottleneck(x, int(48*scalling), (5, 5), e=3, s=1, squeeze=True, nl='HS')\n",
    "    x =  _bottleneck(x, int(48*scalling), (5, 5), e=3, s=1, squeeze=True, nl='HS')\n",
    "    x =  _bottleneck(x, int(96*scalling), (5, 5), e=6, s=2, squeeze=True, nl='HS')\n",
    "    x =  _bottleneck(x, int(96*scalling), (5, 5), e=6, s=1, squeeze=True, nl='HS')\n",
    "    x =  _bottleneck(x, int(120*scalling), (5, 5), e=6, s=1, squeeze=True, nl='HS')\n",
    "\n",
    "    x =  _conv_block(x, int(576*scalling), (1, 1), strides=(1, 1), nl='HS')\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Reshape((1, 1, int(576*scalling)))(x)\n",
    "\n",
    "    x = Conv2D(int(1280*scalling), (1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x =  _return_activation(x, 'HS')\n",
    "    \n",
    "    x=Dropout(0.5)(x)\n",
    "    xage = Conv2D(1, (1, 1), padding='same')(x)\n",
    "    xgender=Conv2D(2, (1, 1), padding='same', activation='softmax')(x)\n",
    "    xemo=Conv2D(6, (1, 1), padding='same', activation='softmax')(x)\n",
    "    xconcate=Concatenate()([xage,xgender,xemo])\n",
    "    output = Reshape((9,))(xconcate)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Reshape\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "#from model.mobilenet_base import MobileNetBase\n",
    "\n",
    "\n",
    "\n",
    "def MobileNetV3_Large(shape,n_class,scalling):\n",
    "    \"\"\"build MobileNetV3 Small.\n",
    "\n",
    "    # Arguments\n",
    "        plot: Boolean, weather to plot model.\n",
    "\n",
    "    # Returns\n",
    "        model: Model, model.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=shape)\n",
    "\n",
    "    x = _conv_block(inputs, int(16*scalling), (3, 3), strides=(1, 1), nl='HS')\n",
    "\n",
    "    x = _bottleneck(x, int(16*scalling), (3, 3), e=1, s=1, squeeze=False, nl='RE')\n",
    "    x = _bottleneck(x, int(24*scalling), (3, 3), e=4, s=2, squeeze=False, nl='RE')\n",
    "    x = _bottleneck(x, int(24*scalling), (3, 3), e=3, s=1, squeeze=False, nl='RE')\n",
    "    x = _bottleneck(x, int(40*scalling), (5, 5), e=3, s=2, squeeze=True, nl='RE')\n",
    "    x = _bottleneck(x, int(40*scalling), (5, 5), e=3, s=1, squeeze=True, nl='RE')\n",
    "    x = _bottleneck(x, int(40*scalling), (5, 5), e=3, s=1, squeeze=True, nl='RE')\n",
    "    x = _bottleneck(x, int(80*scalling), (3, 3), e=6, s=2, squeeze=False, nl='HS')\n",
    "    x = _bottleneck(x, int(80*scalling), (3, 3), e=3, s=1, squeeze=False, nl='HS')\n",
    "    x = _bottleneck(x, int(80*scalling), (3, 3), e=2, s=1, squeeze=False, nl='HS')\n",
    "    x = _bottleneck(x, int(80*scalling), (3, 3), e=2, s=1, squeeze=False, nl='HS')\n",
    "    x = _bottleneck(x, int(112*scalling), (3, 3), e=6, s=1, squeeze=True, nl='HS')\n",
    "    x = _bottleneck(x, int(112*scalling), (3, 3), e=6, s=1, squeeze=True, nl='HS')\n",
    "    x = _bottleneck(x, int(160*scalling), (5, 5), e=6, s=2, squeeze=True, nl='HS')\n",
    "    x = _bottleneck(x, int(160*scalling), (5, 5), e=6, s=1, squeeze=True, nl='HS')\n",
    "    x = _bottleneck(x, int(160*scalling), (5, 5), e=6, s=1, squeeze=True, nl='HS')\n",
    "\n",
    "    x = _conv_block(x, 960, (1, 1), strides=(1, 1), nl='HS')\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Reshape((1, 1, 960))(x)\n",
    "\n",
    "    x = Conv2D(1280, (1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x =  _return_activation(x, 'HS')\n",
    "    \n",
    "    x=Dropout(0.5)(x)\n",
    "    xage = Conv2D(1, (1, 1), padding='same')(x)\n",
    "    xgender=Conv2D(2, (1, 1), padding='same', activation='softmax')(x)\n",
    "    xemo=Conv2D(6, (1, 1), padding='same', activation='softmax')(x)\n",
    "    xconcate=Concatenate()([xage,xgender,xemo])\n",
    "    output = Reshape((9,))(xconcate)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "\n",
    "\n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def accu5(y_true,y_pred):\n",
    "    y_true=y_true[:,0]\n",
    "    y_pred=y_pred[:,0]\n",
    "    \n",
    "\n",
    "    y_pred = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "    y_true = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "    diff=y_true-y_pred\n",
    "    abss=tf.math.abs(diff)\n",
    "    zeros=tf.zeros(tf.shape(y_true),dtype=tf.dtypes.float32)\n",
    "    ones=tf.ones(tf.shape(y_true),dtype=tf.dtypes.float32)\n",
    "    minuss=abss-(ones*5)\n",
    "    morethan=tf.clip_by_value(\n",
    "    minuss,\n",
    "    0,\n",
    "    15,\n",
    "    name=None\n",
    "    )\n",
    "    elements_equal_to_value = tf.equal(zeros, morethan)\n",
    "    as_ints = tf.cast(elements_equal_to_value, tf.int32)\n",
    "    count = tf.reduce_sum(as_ints)\n",
    "    acc=count/tf.size(y_true)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "def meann(y_true,y_pred):\n",
    "    y_true=y_true[:,0]\n",
    "    y_pred=y_pred[:,0]\n",
    "    \n",
    "\n",
    "    y_pred = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "    y_true = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))  \n",
    "    aa=tf.reduce_mean(tf.abs((y_true-y_pred)))\n",
    "    \n",
    "    return aa\n",
    "\n",
    "\n",
    "\n",
    "def accu10(y_true,y_pred):\n",
    "    y_true=y_true[:,0]\n",
    "    y_pred=y_pred[:,0]\n",
    "    \n",
    "\n",
    "    y_pred = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "    y_true = tf.boolean_mask(y_true, tf.not_equal(y_true, -1)) \n",
    "    diff=y_true-y_pred\n",
    "    abss=tf.math.abs(diff)\n",
    "    zeros=tf.zeros(tf.shape(y_true),dtype=tf.dtypes.float32)\n",
    "    ones=tf.ones(tf.shape(y_true),dtype=tf.dtypes.float32)\n",
    "    minuss=abss-(ones*10)\n",
    "    morethan=tf.clip_by_value(\n",
    "    minuss,\n",
    "    0,\n",
    "    15,\n",
    "    name=None\n",
    "    )\n",
    "    elements_equal_to_value = tf.equal(zeros, morethan)\n",
    "    as_ints = tf.cast(elements_equal_to_value, tf.int32)\n",
    "    count = tf.reduce_sum(as_ints)\n",
    "    acc=count/tf.size(y_true)\n",
    "    return acc\n",
    "\n",
    "def accu15(y_true,y_pred):\n",
    "    y_true=y_true[:,0]\n",
    "    y_pred=y_pred[:,0]\n",
    "    \n",
    "\n",
    "    y_pred = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "    y_true = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "    \n",
    "    diff=y_true-y_pred\n",
    "    abss=tf.math.abs(diff)\n",
    "    zeros=tf.zeros(tf.shape(y_true),dtype=tf.dtypes.float32)\n",
    "    ones=tf.ones(tf.shape(y_true),dtype=tf.dtypes.float32)\n",
    "    minuss=abss-(ones*15)\n",
    "    morethan=tf.clip_by_value(\n",
    "    minuss,\n",
    "    0,\n",
    "    15,\n",
    "    name=None\n",
    "    )\n",
    "    elements_equal_to_value = tf.equal(zeros, morethan)\n",
    "    as_ints = tf.cast(elements_equal_to_value, tf.int32)\n",
    "    count = tf.reduce_sum(as_ints)\n",
    "    acc=count/tf.size(y_true)\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def accu15perc(y_true,y_pred):\n",
    "    y_true=y_true[:,0]\n",
    "    y_pred=y_pred[:,0]\n",
    "    \n",
    "\n",
    "    y_pred = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "    y_true = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "    \n",
    "    \n",
    "    zeros=tf.zeros(tf.shape(y_true),dtype=tf.dtypes.float32)\n",
    "    ones=tf.ones(tf.shape(y_true),dtype=tf.dtypes.float32)\n",
    "    percentage=y_pred/y_true\n",
    "    diff=percentage-ones #diff in percent\n",
    "    abss=tf.math.abs(diff)\n",
    "\n",
    "    minuss=abss-(ones*0.15)\n",
    "    morethan=tf.clip_by_value(\n",
    "    minuss,\n",
    "    0,\n",
    "    15,\n",
    "    name=None\n",
    "    )\n",
    "    elements_equal_to_value = tf.equal(zeros, morethan)\n",
    "    as_ints = tf.cast(elements_equal_to_value, tf.int32)\n",
    "    count = tf.reduce_sum(as_ints)\n",
    "    acc=count/tf.size(y_true)\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "def accu25perc(y_true,y_pred):\n",
    "    \n",
    "    \n",
    "    y_true=y_true[:,0]\n",
    "    y_pred=y_pred[:,0]\n",
    "    \n",
    "\n",
    "    y_pred = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "    y_true = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "\n",
    "    \n",
    "    zeros=tf.zeros(tf.shape(y_true),dtype=tf.dtypes.float32)\n",
    "    ones=tf.ones(tf.shape(y_true),dtype=tf.dtypes.float32)\n",
    "    percentage=y_pred/y_true\n",
    "    diff=percentage-ones #diff in percent\n",
    "    abss=tf.math.abs(diff)\n",
    "\n",
    "    minuss=abss-(ones*0.25)\n",
    "    morethan=tf.clip_by_value(\n",
    "    minuss,\n",
    "    0,\n",
    "    15,\n",
    "    name=None\n",
    "    )\n",
    "    elements_equal_to_value = tf.equal(zeros, morethan)\n",
    "    as_ints = tf.cast(elements_equal_to_value, tf.int32)\n",
    "    count = tf.reduce_sum(as_ints)\n",
    "    acc=count/tf.size(y_true)\n",
    "    return acc\n",
    "\n",
    "def accu30perc(y_true,y_pred):\n",
    "    \n",
    "    \n",
    "    y_true=y_true[:,0]\n",
    "    y_pred=y_pred[:,0]\n",
    "    \n",
    "\n",
    "    y_pred = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "    y_true = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "\n",
    "    \n",
    "    zeros=tf.zeros(tf.shape(y_true),dtype=tf.dtypes.float32)\n",
    "    ones=tf.ones(tf.shape(y_true),dtype=tf.dtypes.float32)\n",
    "    percentage=y_pred/y_true\n",
    "    diff=percentage-ones #diff in percent\n",
    "    abss=tf.math.abs(diff)\n",
    "\n",
    "    minuss=abss-(ones*0.30)\n",
    "    morethan=tf.clip_by_value(\n",
    "    minuss,\n",
    "    0,\n",
    "    15,\n",
    "    name=None\n",
    "    )\n",
    "    elements_equal_to_value = tf.equal(zeros, morethan)\n",
    "    as_ints = tf.cast(elements_equal_to_value, tf.int32)\n",
    "    count = tf.reduce_sum(as_ints)\n",
    "    acc=count/tf.size(y_true)\n",
    "    return acc\n",
    "\n",
    "def genderAccu(y_true,y_pred):\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_true=y_true[:,1]\n",
    "    y_pred=y_pred[:,1:3]\n",
    "    y_pred1 = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "    y_true1 = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "    \n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true1, y_pred1)\n",
    "\n",
    "def emoAccu(y_true,y_pred):\n",
    "    y_true=y_true[:,2]\n",
    "    y_pred=y_pred[:,3:9]\n",
    "    y_pred1 = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "    y_true1 = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLoss(yTrue,yPred):\n",
    "    ageYTrue=yTrue[:,0]\n",
    "    ageYPred=yPred[:,0]\n",
    "    #print('yTrue',yTrue)\n",
    "    #print('yPred',yPred)\n",
    "    genderYTrue=yTrue[:,1]\n",
    "    genderYPred=yPred[:,1:3]\n",
    "    emoYTrue=yTrue[:,2]\n",
    "    emoYPred=yPred[:,3:9]\n",
    "    \n",
    "    ageYTrue_masked = tf.boolean_mask(ageYTrue, tf.not_equal(ageYTrue, -1))\n",
    "    ageYPred_masked = tf.boolean_mask(ageYPred, tf.not_equal(ageYTrue, -1))\n",
    "    \n",
    "   # print('genderYTrue',genderYTrue)\n",
    "   # print('genderYPred',genderYPred)\n",
    "   # print('tf.not_equal(genderYTrue, -1)',tf.not_equal(genderYTrue, -1))\n",
    "    genderYTrue_masked = tf.boolean_mask(genderYTrue, tf.not_equal(genderYTrue, -1))\n",
    "    genderYPred_masked = tf.boolean_mask(genderYPred, tf.not_equal(genderYTrue, -1))\n",
    "    \n",
    "   # print('genderYTrue_masked',genderYTrue_masked)\n",
    "   # print('genderYPred_masked',genderYPred_masked)\n",
    "    emoYTrue_masked = tf.boolean_mask(emoYTrue, tf.not_equal(emoYTrue, -1))\n",
    "    emoYPred_masked = tf.boolean_mask(emoYPred, tf.not_equal(emoYTrue, -1))\n",
    "    \n",
    "    ageLoss=tf.keras.losses.logcosh(ageYTrue_masked, ageYPred_masked)\n",
    "    genderLoss=tf.keras.losses.sparse_categorical_crossentropy(genderYTrue_masked,genderYPred_masked)\n",
    "    emoLoss=tf.keras.losses.sparse_categorical_crossentropy(emoYTrue_masked,emoYPred_masked)\n",
    "    \n",
    "    loss_op=(\n",
    "       K.mean(ageLoss)+K.mean(genderLoss)*12+K.mean(emoLoss)*8\n",
    "    )\n",
    "    \n",
    "    return loss_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "custom_objects={'_return_activation': _return_activation,'_conv_block':_conv_block,'_bottleneck':_bottleneck,\n",
    "    '_return_activation':_return_activation,'_hard_swish':_hard_swish,'_relu6':_relu6,'accu5':accu5,'accu10':accu10,'accu15':accu15,'accu15perc':accu15perc,'accu25perc':accu25perc,'accu30perc':accu30perc,'meann':meann,'ageLoss':ageLoss,'genderLoss':genderLoss,'emoLoss':emoLoss,'customLoss':customLoss,'genderAccu':genderAccu,'emoAccu':emoAccu}\n",
    "\n",
    "\n",
    "#model = load_model('./models/best_weights.hdf5', custom_objects=custom_objects)\n",
    "#model = load_model('./models/best_weights 14_28595.hdf5', custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Single-worker CollectiveAllReduceStrategy with local_devices = ('/device:GPU:0',), communication = CollectiveCommunication.AUTO\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import *\n",
    "adam=tf.keras.optimizers.Adam(lr=0.001,beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "#model.compile(loss=customLoss, optimizer=adam) \n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                              patience=4, min_lr=0.0000002)\n",
    "#earlystopping=EarlyStopping(monitor='val_loss', patience=10, verbose=2)\n",
    "\n",
    "mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "#with mirrored_strategy.scope():\n",
    "model=MobileNetV3_Large((112,112,3),9,1.5)\n",
    "model.compile(loss=customLoss, optimizer=adam,metrics=[accu5,accu10,accu15,accu15perc,accu25perc,accu30perc,meann,ageLoss,genderLoss,emoLoss,emoAccu,genderAccu]) \n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"./models/best_weights.hdf5\", \n",
    "                               monitor = 'val_loss',\n",
    "                               mode='min',\n",
    "                               verbose=1, \n",
    "                               save_best_only=True)\n",
    "tensorboard=TensorBoard(log_dir='./logs')\n",
    "callbackss=[checkpointer,tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,  img_to_array, load_img\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "(67971, 112, 112, 3)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_grad.py:502: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n",
      " 44/272 [===>..........................] - ETA: 2:32 - loss: 54.0168 - accu5: 0.0168 - accu10: 0.0452 - accu15: 0.0865 - accu15perc: 0.0112 - accu25perc: 0.0213 - accu30perc: 0.0264 - meann: 33.5737 - ageLoss: 32.8817 - genderLoss: 8.9405 - emoLoss: 12.1946 - emoAccu: 0.4815 - genderAccu: 0.5940"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-1:\n",
      "Process Keras_worker_ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 571, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/numpy_array_iterator.py\", line 153, in _get_batches_of_transformed_samples\n",
      "    x.astype(self.dtype), params)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\", line 870, in apply_transform\n",
      "    order=self.interpolation_order)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/affine_transformations.py\", line 333, in apply_affine_transform\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/affine_transformations.py\", line 333, in <listcomp>\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 458, in affine_transform\n",
      "    output, order, mode, cval, None, None)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-dd81a45121a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                         \u001b[0;31m#validation_steps=60,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                         callbacks = callbackss)\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m               training=training))\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-e2e59441d583>\u001b[0m in \u001b[0;36m_hard_swish\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m6.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_return_activation\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    910\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_truediv_python3\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1003\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mreal_div\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   7929\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   7930\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RealDiv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7931\u001b[0;31m         name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[1;32m   7932\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7933\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### !!!!!!!!!!!! fIX flip\n",
    "\n",
    "import gc\n",
    "from random import randrange\n",
    "\n",
    "#generator = ImageDataGenerator_landmarks()\n",
    "#valix, valiy = validation_generator\n",
    "#image, y = training_generator\n",
    "\n",
    "image=inputarraytrain\n",
    "y=labelarraytrain\n",
    "\n",
    "valix=inputarraytest\n",
    "valiy=labelarraytest\n",
    "\n",
    "#y=listimagewithlabel\n",
    "\n",
    "\n",
    "#with tf.device(\"device:XLA_GPU:1\"):\n",
    "for i in range (1000):\n",
    "    if (i !=0):\n",
    "        del datagen\n",
    "    gc.collect()\n",
    "    datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=[0.8,1.2]\n",
    "    )\n",
    "\n",
    "    i11=i%6\n",
    "    print('i:',i)\n",
    "    traincnt=int(inputarraytrain.shape[0]/6)-1\n",
    "    valicnt=int(inputarraytest.shape[0]/4)-1\n",
    "\n",
    "    imageportion=inputarraytrain[traincnt*i11:traincnt*(i11+1)]\n",
    "    labelportion=labelarraytrain[traincnt*i11:traincnt*(i11+1)]\n",
    "    listk=np.random.choice(range(inputarraytest.shape[0]), inputarraytest.shape[0]//4, replace=False)\n",
    "\n",
    "    testimageportion=inputarraytest[listk]\n",
    "    testlabelportion=labelarraytest[listk]\n",
    "    print(imageportion.shape)\n",
    "\n",
    "    #print('labelportion[0]:',labelportion[0])\n",
    "\n",
    "\n",
    "\n",
    "    train_history = model.fit_generator(\n",
    "\n",
    "                        datagen.flow(imageportion, labelportion, batch_size=250),\n",
    "                        #steps_per_epoch=500,\n",
    "                        steps_per_epoch=int(imageportion.shape[0]/250)+1,\n",
    "        validation_data=(testimageportion, testlabelportion),\n",
    "        epochs=1,\n",
    "                        max_queue_size=2,\n",
    "                        workers = 2 ,\n",
    "                        use_multiprocessing=True,\n",
    "                        #validation_steps=60,\n",
    "                        callbacks = callbackss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "history = model.fit(x=image,y=y,\n",
    "                    batch_size=300,\n",
    "                    #steps_per_epoch=900,\n",
    "                    epochs=500,validation_data=(valix, valiy),\n",
    "                    validation_steps=60\n",
    "                    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_history = model.fit_generator(\n",
    "\n",
    "                        datagen.flow(imageportion, labelportion, batch_size=250),\n",
    "                        #steps_per_epoch=500,\n",
    "                        steps_per_epoch=int(imageportion.shape[0]/250)+1,\n",
    "        validation_data=(testimageportion, testlabelportion),\n",
    "        epochs=1,\n",
    "                        max_queue_size=2,\n",
    "                        workers = 2 ,\n",
    "                        use_multiprocessing=True,\n",
    "                        #validation_steps=60,\n",
    "                        callbacks = callbackss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    train_history = model.fit(\n",
    "\n",
    "                        datagen.flow(imageportion, labelportion, batch_size=250),\n",
    "                        #steps_per_epoch=500,\n",
    "                        steps_per_epoch=int(imageportion.shape[0]/250)+1,\n",
    "        validation_data=(testimageportion, testlabelportion),\n",
    "        epochs=1,\n",
    "        shuffle=False,\n",
    "                       # max_queue_size=2,\n",
    "                      #  workers = 2 ,\n",
    "                     #   use_multiprocessing=True,\n",
    "                        #validation_steps=60,\n",
    "                        callbacks = callbackss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputarraytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset_selective -f labelarraytrain\n",
    "%reset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "image=inputarraytrain\n",
    "y=labelarraytrain\n",
    "valix=inputarraytest\n",
    "valiy=labelarraytest\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "   # featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rotation_range=15,\n",
    "    zoom_range=[0.4,1.0],\n",
    "    brightness_range=[0.8,1.1],\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0,\n",
    "    horizontal_flip=True)\n",
    "datagen.fit(valix)\n",
    "it = datagen.flow(image[:100], y[0:100], batch_size=5)\n",
    "\n",
    "for i in range(20):\n",
    "    # define subplot\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    # generate batch of images\n",
    "    batch = it.next()\n",
    "    # convert to unsigned integers for viewing\n",
    "    image = batch[0][0].astype('uint8')\n",
    "    # plot raw pixel data\n",
    "    print(image.shape)\n",
    "    print(batch[1][0])\n",
    "    pyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "datapath='./dataarray/three_attributes/'\n",
    "inputarraytest=np.load(datapath+'theImageArraytest.npy')\n",
    "\n",
    "labelarraytest=np.load(datapath+'theLabelArraytest.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "fromtestarray=0\n",
    "onlyWrongOnes=1\n",
    "#path ='./fd2/img_celeba_resize/'\n",
    "path ='./'\n",
    "files = os.listdir(path)\n",
    "index = random.randrange(0, len(files))\n",
    "\n",
    "wronglist=[]\n",
    "from tensorflow.keras.preprocessing import image as imakeras\n",
    "for i in range (inputarraytest.shape[0]):\n",
    "    \n",
    "    #print(inputarraytest.shape)\n",
    "    #print(labelarraytest.shape)\n",
    "    if(fromtestarray==1):\n",
    "        \n",
    "        #index = random.randrange(0,inputarraytest.shape[0] )\n",
    "        index = i\n",
    "        img = inputarraytest[index]\n",
    "        img_tensor = imakeras.img_to_array(img)\n",
    "    else:\n",
    "        index = random.randrange(0, len(files))\n",
    "    \n",
    "        img = imakeras.load_img(path+'11w2.png', target_size=(112, 112))\n",
    "        img_tensor = imakeras.img_to_array(img)\n",
    "        img_tensor = img_tensor[:,:,::-1]\n",
    "    #img = imakeras.load_img('./geg.jpg', target_size=(40, 40))\n",
    "    #print(img)\n",
    "\n",
    "    \n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "\n",
    "    \n",
    "\n",
    "    img_tensor=np.concatenate((img_tensor,img_tensor))#2\n",
    "    img_tensor=np.concatenate((img_tensor,img_tensor))#4\n",
    "    img_tensor=np.concatenate((img_tensor,img_tensor))#8\n",
    "  #  img_tensor=np.concatenate((img_tensor,img_tensor))#16\n",
    "  #  img_tensor=np.concatenate((img_tensor,img_tensor))#32\n",
    "  #  img_tensor=np.concatenate((img_tensor,img_tensor))#64\n",
    "  #  img_tensor=np.concatenate((img_tensor,img_tensor))#128\n",
    "    start_time = time.time()\n",
    "    aa=model.predict(img_tensor,steps=1)\n",
    "    #print('aa:',aa)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    aa=aa[0]\n",
    "    label=labelarraytest[index]\n",
    "    #print('argmax(aa',np.argmax(aa))\n",
    "    #print(aa.shape)\n",
    "\n",
    "    #if(np.argmax(aa)!=5):\n",
    "        #continue\n",
    "    \n",
    "    #print(aa[0])\n",
    "   # if(aa-label<8 and aa-label>-8):\n",
    "     #   continue\n",
    "\n",
    "    \n",
    "    print(\"ela\"+str(elapsed_time))\n",
    "\n",
    "    print('index: ', index)\n",
    "    print('pd: ',aa)\n",
    "\n",
    "    print('label: ',label)\n",
    "   # print('name: ',namearraytest[index])\n",
    "   # wronglist.append(namearraytest[index])\n",
    "    if(fromtestarray==1):\n",
    "        img = img[:,:,::-1]\n",
    "   # print(img.shape)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#reduce weight of happiness\n",
    "#need to be able to classify child\n",
    "0:neutral\n",
    "1:happiness\n",
    "2:Sadness\n",
    "3:Surprise\n",
    "4:Fear\n",
    "5:Disgust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('./models/best_weights.hdf5',custom_objects={'customLoss': customLoss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = load_model('./models/kerasmodelSmaller/best_weights.hdf5',custom_objects={'customLoss': customLoss})\n",
    "from kerasulti import *\n",
    "from tensorflow.core.framework import attr_value_pb2\n",
    "from tensorflow.core.framework import graph_pb2\n",
    "from tensorflow.core.framework import node_def_pb2\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from tensorflow.python.util import deprecation\n",
    "from tensorflow.python.util.tf_export import tf_export\n",
    "from tensorflow.python.tools import import_pb_to_tensorboard\n",
    "#convert hdf5 to pb\n",
    "input_path = './models/kerasmodelSmall/'\n",
    "weight_file = 'best_weights.hdf5'\n",
    "weight_file_path = osp.join(input_path,weight_file)\n",
    "output_graph_name = weight_file[:-5] + '.pb'\n",
    "#轉換函式\n",
    "def h5_to_pb(h5_model,output_dir,model_name,out_prefix = \"output_\",log_tensorboard = True):\n",
    "    if osp.exists(output_dir) == False:\n",
    "        os.mkdir(output_dir)\n",
    "    out_nodes = []\n",
    "    for i in range(len(h5_model.outputs)):\n",
    "        out_nodes.append(out_prefix + str(i + 1))\n",
    "        tf.identity(h5_model.output[i],out_prefix + str(i + 1))\n",
    "    sess = K.get_session()\n",
    "    from tensorflow.python.framework import graph_util,graph_io\n",
    "    init_graph = sess.graph.as_graph_def()\n",
    "    main_graph = convert_variables_to_constants(sess,init_graph,out_nodes)\n",
    "    graph_io.write_graph(main_graph,output_dir,name = model_name,as_text = False)\n",
    "    if log_tensorboard:\n",
    "\n",
    "        import_pb_to_tensorboard.import_to_tensorboard(osp.join(output_dir,model_name),output_dir)\n",
    "#輸出路徑\n",
    "output_dir = osp.join(os.getcwd(),\"trans_model\")\n",
    "#載入模型\n",
    "h5_model = load_model(weight_file_path, custom_objects={'customLoss': customLoss})\n",
    "h5_to_pb(h5_model,output_dir = output_dir,model_name = output_graph_name)\n",
    "print('model saved')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#the pb frozen with following code can be converted to tflite\n",
    "import os \n",
    "import os.path as osp\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.core.framework import attr_value_pb2\n",
    "from tensorflow.core.framework import graph_pb2\n",
    "from tensorflow.core.framework import node_def_pb2\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from tensorflow.python.util import deprecation\n",
    "from tensorflow.python.util.tf_export import tf_export\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "model = load_model('./models/best_weights.hdf5',custom_objects= customLoss)\n",
    "\n",
    "print(model.outputs)\n",
    "# [<tf.Tensor 'dense_2/Softmax:0' shape=(?, 10) dtype=float32>]\n",
    "print(model.inputs)\n",
    "# [<tf.Tensor 'conv2d_1_input:0' shape=(?, 28, 28, 1) dtype=float32>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import import_pb_to_tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.outputs)\n",
    "# [<tf.Tensor 'dense_2/Softmax:0' shape=(?, 10) dtype=float32>]\n",
    "print(model.inputs)\n",
    "\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        # Graph -> GraphDef ProtoBuf\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph\n",
    "\n",
    "\n",
    "frozen_graph = freeze_session(K.get_session(),\n",
    "                              output_names=[out.op.name for out in model.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save to ./model/tf_model.pb\n",
    "tf.train.write_graph(frozen_graph, \"trans_model/\", \"tf_model.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_frozen_graph('trans_model/tf_model.pb', ['input_1'], ['dense_1/BiasAdd'])\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import import_pb_to_tensorboard\n",
    "import_pb_to_tensorboard.import_to_tensorboard('trans_model/small/tf_model.pb','/workspace/testbuildmodel/lanes/trans_model/small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valix)\n",
    "print(valiy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
